# üê≥ Guide de d√©ploiement Docker - Generic Scraper V2

Ce guide explique comment d√©ployer Generic Scraper V2 avec Docker et Docker Compose.

## üìã Pr√©requis

- Docker Engine 20.10+
- Docker Compose 2.0+
- 2 GB RAM minimum
- 5 GB espace disque

## üöÄ D√©marrage rapide

### 1. Cloner le projet

```bash
git clone <repository-url>
cd generic-scraper
```

### 2. Configuration des variables d'environnement (optionnel)

```bash
# Copier le fichier d'exemple
cp .env.example .env

# √âditer si n√©cessaire
# Les valeurs par d√©faut fonctionnent pour un d√©ploiement local
```

### 3. Lancer l'application

```bash
# Construire et d√©marrer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f

# Arr√™ter les services
docker-compose down
```

### 4. Acc√©der √† l'application

- **Frontend** : http://localhost:3000
- **Backend API** : http://localhost:4000
- **Health Check** : http://localhost:4000/api/health

## üì¶ Services

### Frontend (Vue.js)
- **Port** : 3000
- **Image** : Node.js 20 Alpine + Nginx Alpine
- **Build** : Multi-stage (build + production)

### Backend (Express)
- **Port** : 4000
- **Image** : Node.js 20 Alpine
- **Build** : Multi-stage (build + production)
- **Volumes** :
  - `./configs` ‚Üí `/app/configs` (Configurations de scraping)
  - `./logs` ‚Üí `/app/logs` (Logs d'ex√©cution)
  - `./output` ‚Üí `/app/output` (Donn√©es extraites)
  - `./data` ‚Üí `/app/data` (Base de donn√©es SQLite)
  - `./src` ‚Üí `/app/src` (Moteur de scraping)

## üîß Commandes utiles

### Gestion des services

```bash
# D√©marrer les services
docker-compose up -d

# Arr√™ter les services
docker-compose down

# Red√©marrer un service
docker-compose restart backend
docker-compose restart frontend

# Voir les logs
docker-compose logs -f
docker-compose logs -f backend
docker-compose logs -f frontend

# Voir le statut
docker-compose ps
```

### Rebuild et mise √† jour

```bash
# Reconstruire les images
docker-compose build

# Reconstruire sans cache
docker-compose build --no-cache

# Reconstruire et red√©marrer
docker-compose up -d --build
```

### Acc√®s aux conteneurs

```bash
# Shell dans le backend
docker-compose exec backend sh

# Shell dans le frontend
docker-compose exec frontend sh

# Ex√©cuter une commande dans le backend
docker-compose exec backend npm run lint
```

### Gestion des volumes

```bash
# Lister les volumes
docker volume ls

# Inspecter un volume
docker volume inspect generic-scraper_data

# Supprimer les volumes (‚ö†Ô∏è perte de donn√©es)
docker-compose down -v
```

## üîç Debugging

### V√©rifier la sant√© des services

```bash
# Health check du backend
curl http://localhost:4000/api/health

# Informations de l'API
curl http://localhost:4000/api/info
```

### Logs d√©taill√©s

```bash
# Logs avec timestamps
docker-compose logs -f --timestamps

# Derni√®res 100 lignes
docker-compose logs --tail=100
```

### Probl√®mes courants

#### Le frontend ne se connecte pas au backend

1. V√©rifier que le backend est d√©marr√© :
   ```bash
   docker-compose ps
   ```

2. V√©rifier les variables d'environnement :
   ```bash
   docker-compose exec frontend env | grep VITE
   ```

3. V√©rifier la configuration CORS du backend

#### Erreur de build

```bash
# Nettoyer et reconstruire
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

#### Probl√®me de permissions sur les volumes

```bash
# Sur Linux/Mac, ajuster les permissions
sudo chown -R $USER:$USER ./configs ./logs ./output ./data
```

## üåê D√©ploiement en production

### 1. Modifier les variables d'environnement

```bash
# .env
NODE_ENV=production
VITE_API_URL=https://api.votre-domaine.com
VITE_WS_URL=wss://api.votre-domaine.com
CORS_ORIGIN=https://votre-domaine.com
LOG_LEVEL=warn
```

### 2. Utiliser un reverse proxy (Nginx/Traefik)

Exemple de configuration Nginx :

```nginx
server {
    listen 80;
    server_name votre-domaine.com;

    location / {
        proxy_pass http://localhost:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}

server {
    listen 80;
    server_name api.votre-domaine.com;

    location / {
        proxy_pass http://localhost:4000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    location /socket.io {
        proxy_pass http://localhost:4000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### 3. Sauvegardes automatiques

```bash
# Script de backup (backup.sh)
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
tar -czf backup_$DATE.tar.gz ./data ./configs ./output
```

## üìä Monitoring

### Ressources utilis√©es

```bash
# Statistiques en temps r√©el
docker stats

# Espace disque des images
docker system df
```

### Health checks

Les services incluent des health checks automatiques :
- Backend : v√©rifie `/api/health` toutes les 30s
- Frontend : v√©rifie la disponibilit√© de nginx toutes les 30s

## üßπ Nettoyage

```bash
# Arr√™ter et supprimer les conteneurs
docker-compose down

# Supprimer aussi les volumes (‚ö†Ô∏è perte de donn√©es)
docker-compose down -v

# Nettoyer les images non utilis√©es
docker image prune -a

# Nettoyage complet du syst√®me Docker
docker system prune -a --volumes
```

## üìù Notes

- Les volumes sont persistants et conservent les donn√©es entre les red√©marrages
- Le moteur de scraping existant (`./src`) est mont√© en volume pour permettre les modifications √† chaud
- Les logs sont accessibles dans `./logs` m√™me apr√®s l'arr√™t des conteneurs
- La base de donn√©es SQLite est dans `./data/scraper.db`

## üÜò Support

Pour plus d'informations :
- Documentation compl√®te : `./documentation/plan_v2.md`
- Backend README : `./backend/README.md`
- Frontend README : `./frontend/README.md`
